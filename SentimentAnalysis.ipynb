{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3ceb4f-3adc-49cd-8274-d533b7ed312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import os\n",
    "from groq import Groq\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from dotenv import load_dotenv\n",
    "import torch_directml\n",
    "import emoji\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efab1ce8-1854-4b36-8ff4-96b811af68bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.], device='privateuseone:0')\n",
      "tensor([2., 4., 6., 8.], device='privateuseone:0')\n"
     ]
    }
   ],
   "source": [
    "# Inizializzare DirectML\n",
    "device = torch_directml.device()\n",
    "\n",
    "# Esempio di tensore su GPU AMD tramite DirectML\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0], device=device)\n",
    "print(x)\n",
    "\n",
    "# Esegui qualche operazione\n",
    "y = x * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae3fa4d-ad02-4a16-9a6a-d75ae755408e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading danofer/sarcasm...\n",
      "Dataset URL: https://www.kaggle.com/datasets/danofer/sarcasm\n",
      "Download completato!\n",
      "\n",
      "File scaricati:\n",
      "- test-balanced.csv\n",
      "- test-unbalanced.csv\n",
      "- train-balanced-sarc.csv.gz\n",
      "- train-balanced-sarcasm.csv\n"
     ]
    }
   ],
   "source": [
    "def download_kaggle_dataset(dataset, path):\n",
    "    kaggle.api.dataset_download_files(dataset, path=path, unzip=True)\n",
    "\n",
    "# Specifica il dataset che vuoi scaricare\n",
    "dataset = \"danofer/sarcasm\"  # Dataset di sarcasmo\n",
    "\n",
    "# Specifica la directory in cui salvare il dataset\n",
    "save_dir = \"./datasets/\"\n",
    "\n",
    "# Crea la directory se non esiste\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Scarica il dataset\n",
    "print(f\"Downloading {dataset}...\")\n",
    "download_kaggle_dataset(dataset, save_dir)\n",
    "\n",
    "print(\"Download completato!\")\n",
    "\n",
    "# Lista i file scaricati\n",
    "print(\"\\nFile scaricati:\")\n",
    "for file in os.listdir(save_dir):\n",
    "    print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ffac72a-cdba-4418-b66a-19893cba3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizzo del dispositivo DirectML\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch_directml\n",
    "    device = torch_directml.device()\n",
    "    print(\"Utilizzo del dispositivo DirectML\")\n",
    "except ImportError:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"DirectML non disponibile, utilizzo di {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "241ca02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dei dati...\n",
      "Pulizia del dataset in corso...\n",
      "Dataset pulito e filtrato. Dimensioni del nuovo DataFrame: (200000, 3)\n",
      "\n",
      "Prime 5 righe del DataFrame pulito:\n",
      "   label                                            comment  \\\n",
      "1      0  You do know west teams play against west teams...   \n",
      "2      0  They were underdogs earlier today, but since G...   \n",
      "3      0  This meme isn't funny none of the \"new york ni...   \n",
      "4      0                    I could use one of those tools.   \n",
      "5      0  I don't pay attention to her, but as long as s...   \n",
      "\n",
      "                                     cleaned_comment  \n",
      "1  you do know west teams play against west teams...  \n",
      "2  they were underdogs earlier today but since gr...  \n",
      "3  this meme isnt funny none of the new york nigg...  \n",
      "4                     i could use one of those tools  \n",
      "5  i dont pay attention to her but as long as she...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from collections import Counter\n",
    "\n",
    "df_file = os.path.join(\"datasets\", \"train-balanced-sarcasm.csv\")\n",
    "\n",
    "# Funzione per pulire il testo\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'http\\S+', '', text)  # Rimuove URL\n",
    "    text = re.sub(r'@\\w+', '', text)  # Rimuove menzioni\n",
    "    text = re.sub(r'#\\w+', '', text)  # Rimuove hashtag\n",
    "    text = re.sub(r'\\d+', '', text)  # Rimuove numeri\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Rimuove punteggiatura\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Funzione per verificare se il testo è valido\n",
    "def is_valid_text(text):\n",
    "    # Rimuove emoji\n",
    "    text = emoji.replace_emoji(text, '')\n",
    "    # Rimuove spazi extra\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Verifica se il testo ha almeno 3 parole e più di 10 caratteri\n",
    "    words = text.split()\n",
    "    \n",
    "    # Verifica se ci sono parole ripetute più di 5 volte\n",
    "    word_counts = Counter(words)\n",
    "    if any(count > 5 for count in word_counts.values()):\n",
    "        return False\n",
    "    \n",
    "    return len(words) >= 3 and len(text) > 10 and not text.isnumeric()\n",
    "\n",
    "# Carica i dati\n",
    "print(\"Caricamento dei dati...\")\n",
    "df = pd.read_csv(df_file)\n",
    "df = df[[\"label\", \"comment\"]]\n",
    "\n",
    "# Pulizia del dataset\n",
    "print(\"Pulizia del dataset in corso...\")\n",
    "df['cleaned_comment'] = df['comment'].apply(clean_text)\n",
    "df['is_valid'] = df['cleaned_comment'].apply(is_valid_text)\n",
    "df = df[df['is_valid']]\n",
    "df = df.drop('is_valid', axis=1)\n",
    "df['comment'] = df['comment'].astype(str)\n",
    "\n",
    "# Campionamento\n",
    "sample = 200000\n",
    "df = df.head(sample)\n",
    "\n",
    "df.to_csv(\"train-balanced-sarcasm-cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Dataset pulito e filtrato. Dimensioni del nuovo DataFrame:\", df.shape)\n",
    "print(\"\\nPrime 5 righe del DataFrame pulito:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f35c4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dei modelli e dei tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matte\\anaconda3\\envs\\base_conda_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Carica i modelli pre-addestrati e i tokenizer\n",
    "print(\"Caricamento dei modelli e dei tokenizer...\")\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name1).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name1)\n",
    "\n",
    "# Crea i pipeline per l'analisi del sentiment\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model1, tokenizer=tokenizer1, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19e6beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisi del sentiment in corso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [43:16<00:00, 77.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuzione del sentiment:\n",
      "sentiment\n",
      "Neutro      103211\n",
      "Negativo     68539\n",
      "Positivo     28250\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Alcuni esempi di analisi:\n",
      "Commento originale: Socialism has had such a historically good track record how could you not love it!...\n",
      "Commento pulito: socialism has had such a historically good track record how could you not love it...\n",
      "Sentiment: Positivo\n",
      "Sarcastico: Sì\n",
      "\n",
      "Commento originale: I'm not sure who is the bigger hero here, the person who originally wrote the question or the person...\n",
      "Commento pulito: im not sure who is the bigger hero here the person who originally wrote the question or the person w...\n",
      "Sentiment: Neutro\n",
      "Sarcastico: No\n",
      "\n",
      "Commento originale: Let's be honest, that's the real most frequent misconception regarding rogue decks....\n",
      "Commento pulito: lets be honest thats the real most frequent misconception regarding rogue decks...\n",
      "Sentiment: Negativo\n",
      "Sarcastico: No\n",
      "\n",
      "Commento originale: Am I reading correctly that the MTSO report is dated in January but the FBI report wasn't until Marc...\n",
      "Commento pulito: am i reading correctly that the mtso report is dated in january but the fbi report wasnt until march...\n",
      "Sentiment: Neutro\n",
      "Sarcastico: No\n",
      "\n",
      "Commento originale: You'd rather have healers sit idly clicking character names in the party menu and then clicking skil...\n",
      "Commento pulito: youd rather have healers sit idly clicking character names in the party menu and then clicking skill...\n",
      "Sentiment: Neutro\n",
      "Sarcastico: No\n",
      "\n",
      "Commento originale: the goal crease is the blue area so no penalty if it's in the net...\n",
      "Commento pulito: the goal crease is the blue area so no penalty if its in the net...\n",
      "Sentiment: Neutro\n",
      "Sarcastico: Sì\n",
      "\n",
      "Commento originale: If I were to guess, you probably didn't max out inserter capacity bonus (which is expensive and very...\n",
      "Commento pulito: if i were to guess you probably didnt max out inserter capacity bonus which is expensive and very la...\n",
      "Sentiment: Positivo\n",
      "Sarcastico: No\n",
      "\n",
      "Commento originale: Lots of wine, this year... :-( Wine because we can't win, then wine because we're fucking up our dra...\n",
      "Commento pulito: lots of wine this year  wine because we cant win then wine because were fucking up our draft positio...\n",
      "Sentiment: Negativo\n",
      "Sarcastico: No\n",
      "\n",
      "Commento originale: What did you use to make it?...\n",
      "Commento pulito: what did you use to make it...\n",
      "Sentiment: Neutro\n",
      "Sarcastico: No\n",
      "\n",
      "Commento originale: Yeah, the ford fusion is a really good looking car...\n",
      "Commento pulito: yeah the ford fusion is a really good looking car...\n",
      "Sentiment: Positivo\n",
      "Sarcastico: Sì\n",
      "\n",
      "\n",
      "Dataset con analisi del sentiment salvato in df_with_sentiment.csv\n",
      "\n",
      "Righe totali: 200000\n",
      "Distribuzione del sentiment:\n",
      "sentiment\n",
      "Neutro      51.61%\n",
      "Negativo    34.27%\n",
      "Positivo    14.12%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Funzione per troncare il testo alla lunghezza massima accettata dal modello\n",
    "def truncate_text(text, max_length=512):\n",
    "    words = text.split()\n",
    "    if len(words) > max_length:\n",
    "        return \" \".join(words[:max_length])\n",
    "    return text\n",
    "\n",
    "# Funzione per analizzare il sentiment\n",
    "def analyze_sentiment(text):\n",
    "    try:\n",
    "        truncated_text = truncate_text(text)\n",
    "        result = sentiment_pipeline(truncated_text)[0]\n",
    "        label = result['label']\n",
    "        if label == 'LABEL_0':\n",
    "            return 'Negativo'\n",
    "        elif label == 'LABEL_1':\n",
    "            return 'Neutro'\n",
    "        else:\n",
    "            return 'Positivo'\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'analisi del sentiment per il testo: {text[:50]}...\")\n",
    "        print(f\"Errore: {str(e)}\")\n",
    "        return \"Errore\"\n",
    "\n",
    "# Funzione per processare il dataframe\n",
    "def process_dataframe(df):\n",
    "    tqdm.pandas()\n",
    "    \n",
    "    # Analizza il sentiment\n",
    "    df['sentiment'] = df['cleaned_comment'].progress_apply(analyze_sentiment)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Processa il dataframe\n",
    "print(\"Analisi del sentiment in corso...\")\n",
    "df_processed = process_dataframe(df)\n",
    "\n",
    "# Mostra la distribuzione del sentiment\n",
    "print(\"\\nDistribuzione del sentiment:\")\n",
    "print(df_processed['sentiment'].value_counts())\n",
    "\n",
    "# Mostra alcuni esempi\n",
    "print(\"\\nAlcuni esempi di analisi:\")\n",
    "sample_size = min(10, len(df_processed))\n",
    "for _, row in df_processed.sample(sample_size).iterrows():\n",
    "    print(f\"Commento originale: {row['comment'][:100]}...\")\n",
    "    print(f\"Commento pulito: {row['cleaned_comment'][:100]}...\")\n",
    "    print(f\"Sentiment: {row['sentiment']}\")\n",
    "    print(f\"Sarcastico: {'Sì' if row['label'] == 1 else 'No'}\\n\")\n",
    "\n",
    "# Salva il risultato\n",
    "output_file = 'df_with_sentiment.csv'\n",
    "df_processed.to_csv(output_file, index=False)\n",
    "print(f\"\\nDataset con analisi del sentiment salvato in {output_file}\")\n",
    "\n",
    "# Statistiche finali\n",
    "print(f\"\\nRighe totali: {len(df_processed)}\")\n",
    "print(f\"Distribuzione del sentiment:\")\n",
    "print(df_processed['sentiment'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf281c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "Neutral     103211\n",
      "Negative     68539\n",
      "Positive     28250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_processed = pd.read_csv(os.path.join(\"datasets\", \"df_with_sentiment.csv\"))\n",
    "\n",
    "df_processed = df_processed.drop('cleaned_comment', axis=1, errors='ignore')\n",
    "# Dizionario per la mappatura\n",
    "mappatura = {\n",
    "    'Neutro': 'Neutral',\n",
    "    'Negativo': 'Negative',\n",
    "    'Positivo': 'Positive'\n",
    "}\n",
    "\n",
    "df_processed['sentiment'] = df_processed['sentiment'].map(mappatura)\n",
    "\n",
    "# Verifica il risultato\n",
    "print(df_processed['sentiment'].value_counts(dropna=False))\n",
    "\n",
    "df_processed.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c7959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del file CSV...\n",
      "Aggiustamento del sentiment in base al sarcasmo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [00:01<00:00, 151171.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuzione del sentiment originale:\n",
      "sentiment\n",
      "Neutral     51.61%\n",
      "Negative    34.27%\n",
      "Positive    14.12%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Distribuzione del sentiment aggiustato:\n",
      "adjusted_sentiment\n",
      "Neutral     51.61%\n",
      "Negative    34.27%\n",
      "Positive    14.12%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Dataset con sentiment aggiustato salvato in df_with_adjusted_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "def adjust_sentiment(row):\n",
    "    if row['label'] == 1:  # Se è sarcasmo\n",
    "        if row['sentiment'] == 'Positivo':\n",
    "            return 'Negativo'\n",
    "        elif row['sentiment'] == 'Negativo':\n",
    "            return 'Positivo'\n",
    "    return row['sentiment']\n",
    "\n",
    "# Carica il file CSV\n",
    "print(\"Caricamento del file CSV...\")\n",
    "df = pd.read_csv(os.path.join(\"datasets\", \"df_with_sentiment.csv\"))\n",
    "\n",
    "# Applica l'aggiustamento del sentiment\n",
    "print(\"Aggiustamento del sentiment in base al sarcasmo...\")\n",
    "tqdm.pandas()\n",
    "df['adjusted_sentiment'] = df.progress_apply(adjust_sentiment, axis=1)\n",
    "\n",
    "# Statistiche finali\n",
    "print(\"Distribuzione del sentiment originale:\")\n",
    "print(df['sentiment'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
    "\n",
    "print(\"\\nDistribuzione del sentiment aggiustato:\")\n",
    "print(df['adjusted_sentiment'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
    "\n",
    "# Salva il risultato\n",
    "output_file = 'df_with_adjusted_sentiment.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nDataset con sentiment aggiustato salvato in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa73ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between sarcasm and positive sentiment: -0.0158\n",
      "All visualizations have been created and saved in the 'graphs' folder.\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'graphs' folder exists\n",
    "os.makedirs('graphs', exist_ok=True)\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(os.path.join(\"datasets\", \"df_with_adjusted_sentiment.csv\"))\n",
    "\n",
    "# Function to create and save word clouds\n",
    "def create_wordcloud(text, title, filename):\n",
    "    wordcloud = WordCloud(width=1600, height=800, \n",
    "                          background_color='white', \n",
    "                          colormap='viridis', \n",
    "                          contour_width=3, \n",
    "                          contour_color='steelblue').generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=24, pad=20)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(os.path.join('graphs', filename), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Word clouds for sarcasm\n",
    "create_wordcloud(' '.join(df[df['label'] == 1]['comment']), 'Common Words in Sarcastic Comments', 'sarcastic_wordcloud.png')\n",
    "create_wordcloud(' '.join(df[df['label'] == 0]['comment']), 'Common Words in Non-Sarcastic Comments', 'non_sarcastic_wordcloud.png')\n",
    "\n",
    "# Word clouds for sentiment\n",
    "for sentiment in ['Positive', 'Neutral', 'Negative']:\n",
    "    create_wordcloud(' '.join(df[df['sentiment'] == sentiment]['comment']), \n",
    "                     f'Common Words in {sentiment} Comments', \n",
    "                     f'{sentiment.lower()}_wordcloud.png')\n",
    "\n",
    "# Correlation between sarcasm and sentiment\n",
    "correlation = df['label'].corr(pd.get_dummies(df['sentiment'])['Positive'])\n",
    "print(f\"Correlation between sarcasm and positive sentiment: {correlation:.4f}\")\n",
    "\n",
    "# Visualize sentiment distribution for sarcastic and non-sarcastic comments\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "ax = sns.countplot(data=df, x='sentiment', hue='label', \n",
    "                   hue_order=[0, 1],\n",
    "                   order=['Positive', 'Neutral', 'Negative'])\n",
    "\n",
    "plt.title('Sentiment Distribution for Sarcastic and Non-Sarcastic Comments', fontsize=16, pad=20)\n",
    "plt.xlabel('Sentiment', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.legend(title='Sarcasm', labels=['Non-Sarcastic', 'Sarcastic'], title_fontsize='13', fontsize='12')\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fontsize=10, padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('graphs', 'sentiment_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"All visualizations have been created and saved in the 'graphs' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472f6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base_conda_env] *",
   "language": "python",
   "name": "conda-env-base_conda_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
