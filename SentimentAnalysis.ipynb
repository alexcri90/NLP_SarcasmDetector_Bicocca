{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c3ceb4f-3adc-49cd-8274-d533b7ed312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import os\n",
    "from groq import Groq\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from dotenv import load_dotenv\n",
    "import torch_directml\n",
    "import emoji\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efab1ce8-1854-4b36-8ff4-96b811af68bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.], device='privateuseone:0')\n",
      "tensor([2., 4., 6., 8.], device='privateuseone:0')\n"
     ]
    }
   ],
   "source": [
    "# Inizializzare DirectML\n",
    "device = torch_directml.device()\n",
    "\n",
    "# Esempio di tensore su GPU AMD tramite DirectML\n",
    "x = torch.tensor([1.0, 2.0, 3.0, 4.0], device=device)\n",
    "print(x)\n",
    "\n",
    "# Esegui qualche operazione\n",
    "y = x * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae3fa4d-ad02-4a16-9a6a-d75ae755408e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading danofer/sarcasm...\n",
      "Dataset URL: https://www.kaggle.com/datasets/danofer/sarcasm\n",
      "Download completato!\n",
      "\n",
      "File scaricati:\n",
      "- test-balanced.csv\n",
      "- test-unbalanced.csv\n",
      "- train-balanced-sarc.csv.gz\n",
      "- train-balanced-sarcasm.csv\n"
     ]
    }
   ],
   "source": [
    "def download_kaggle_dataset(dataset, path):\n",
    "    kaggle.api.dataset_download_files(dataset, path=path, unzip=True)\n",
    "\n",
    "# Specifica il dataset che vuoi scaricare\n",
    "dataset = \"danofer/sarcasm\"  # Dataset di sarcasmo\n",
    "\n",
    "# Specifica la directory in cui salvare il dataset\n",
    "save_dir = \"./datasets/\"\n",
    "\n",
    "# Crea la directory se non esiste\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Scarica il dataset\n",
    "print(f\"Downloading {dataset}...\")\n",
    "download_kaggle_dataset(dataset, save_dir)\n",
    "\n",
    "print(\"Download completato!\")\n",
    "\n",
    "# Lista i file scaricati\n",
    "print(\"\\nFile scaricati:\")\n",
    "for file in os.listdir(save_dir):\n",
    "    print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffac72a-cdba-4418-b66a-19893cba3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizzo del dispositivo DirectML\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch_directml\n",
    "    device = torch_directml.device()\n",
    "    print(\"Utilizzo del dispositivo DirectML\")\n",
    "except ImportError:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"DirectML non disponibile, utilizzo di {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "241ca02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Cleaning the dataset...\n",
      "Performing balanced sampling...\n",
      "Cleaned and balanced dataset saved. New DataFrame dimensions: (200000, 3)\n",
      "\n",
      "First 5 rows of the cleaned DataFrame:\n",
      "   label                                            comment  \\\n",
      "0      0  I've seen people drop gold bars, it's definite...   \n",
      "1      1                             smart, powerful logic.   \n",
      "2      0                I'm sure OP appreciates your input.   \n",
      "3      1  Because they are soldiers of fascist junta who...   \n",
      "4      1  It's a conspiracy, the CIA pre-popped Hillary'...   \n",
      "\n",
      "                                     cleaned_comment  \n",
      "0  ive seen people drop gold bars its definitely ...  \n",
      "1                               smart powerful logic  \n",
      "2                  im sure op appreciates your input  \n",
      "3  because they are soldiers of fascist junta who...  \n",
      "4  its a conspiracy the cia prepopped hillarys pi...  \n",
      "\n",
      "Sarcastic comments: 100000\n",
      "Non-sarcastic comments: 100000\n"
     ]
    }
   ],
   "source": [
    "df_file = os.path.join(\"datasets\", \"train-balanced-sarcasm.csv\")\n",
    "\n",
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Function to check if the text is valid\n",
    "def is_valid_text(text):\n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, '')\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Check if the text has at least 3 words and more than 10 characters\n",
    "    words = text.split()\n",
    "    \n",
    "    # Check if there are words repeated more than 5 times\n",
    "    word_counts = Counter(words)\n",
    "    if any(count > 5 for count in word_counts.values()):\n",
    "        return False\n",
    "    \n",
    "    return len(words) >= 3 and len(text) > 10 and not text.isnumeric()\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(df_file)\n",
    "df = df[[\"label\", \"comment\"]]\n",
    "\n",
    "# Clean the dataset\n",
    "print(\"Cleaning the dataset...\")\n",
    "df['cleaned_comment'] = df['comment'].apply(clean_text)\n",
    "df['is_valid'] = df['cleaned_comment'].apply(is_valid_text)\n",
    "df = df[df['is_valid']]\n",
    "df = df.drop('is_valid', axis=1)\n",
    "df['comment'] = df['comment'].astype(str)\n",
    "\n",
    "# Balanced sampling\n",
    "print(\"Performing balanced sampling...\")\n",
    "sample_size = 100000  # 100,000 per class, 200,000 total\n",
    "df_sarcastic = df[df['label'] == 1].sample(sample_size, random_state=42)\n",
    "df_non_sarcastic = df[df['label'] == 0].sample(sample_size, random_state=42)\n",
    "df_balanced = pd.concat([df_sarcastic, df_non_sarcastic]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the dataset\n",
    "output_file = os.path.join(\"datasets\", \"train-balanced-sarcasm-cleaned.csv\")\n",
    "df_balanced.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Cleaned and balanced dataset saved. New DataFrame dimensions:\", df_balanced.shape)\n",
    "print(\"\\nFirst 5 rows of the cleaned DataFrame:\")\n",
    "print(df_balanced.head())\n",
    "\n",
    "# Verify balance\n",
    "sarcastic_count = df_balanced['label'].sum()\n",
    "non_sarcastic_count = len(df_balanced) - sarcastic_count\n",
    "print(f\"\\nSarcastic comments: {sarcastic_count}\")\n",
    "print(f\"Non-sarcastic comments: {non_sarcastic_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f35c4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dei modelli e dei tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Carica i modelli pre-addestrati e i tokenizer\n",
    "print(\"Caricamento dei modelli e dei tokenizer...\")\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Crea i pipeline per l'analisi del sentiment\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19e6beab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [38:48<00:00, 85.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Neutral     100649\n",
      "Positive     52906\n",
      "Negative     46445\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Some analysis examples:\n",
      "Original comment: That idea sounds retarted....\n",
      "Cleaned comment: that idea sounds retarted...\n",
      "Sentiment: Positive\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: Sipsface looks like a wizard from a storybook....\n",
      "Cleaned comment: sipsface looks like a wizard from a storybook...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: No\n",
      "\n",
      "Original comment: For portable APs, you make sure to throw as much shit on top of the patient's chest as possible....\n",
      "Cleaned comment: for portable aps you make sure to throw as much shit on top of the patients chest as possible...\n",
      "Sentiment: Positive\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: Are you on mac?...\n",
      "Cleaned comment: are you on mac...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: No\n",
      "\n",
      "Original comment: Do you still get paid?...\n",
      "Cleaned comment: do you still get paid...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: Easily Danny Rose, it seems every non-spurs fan thinks of him as a joke, when he is at the moment on...\n",
      "Cleaned comment: easily danny rose it seems every nonspurs fan thinks of him as a joke when he is at the moment one o...\n",
      "Sentiment: Positive\n",
      "Sarcastic: No\n",
      "\n",
      "Original comment: Because the 1070 and 1080 aren't worthy upgrades?...\n",
      "Cleaned comment: because the  and  arent worthy upgrades...\n",
      "Sentiment: Positive\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: [this has derailed **i want the booty**](#yousaidsomethingdumb)...\n",
      "Cleaned comment: this has derailed i want the booty...\n",
      "Sentiment: Negative\n",
      "Sarcastic: No\n",
      "\n",
      "Original comment: So you're playing the Xbone version of Shovel Knight?...\n",
      "Cleaned comment: so youre playing the xbone version of shovel knight...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: TSM seeing a non junglers success(hai) in the jungle they've decided to bench Santorin and test out ...\n",
      "Cleaned comment: tsm seeing a non junglers successhai in the jungle theyve decided to bench santorin and test out a n...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: Yes\n",
      "\n",
      "\n",
      "Dataset with sentiment analysis considering sarcasm saved in datasets\\df_with_sentiment_and_sarcasm.csv\n",
      "\n",
      "Total rows: 200000\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "Neutral     50.32%\n",
      "Positive    26.45%\n",
      "Negative    23.22%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to truncate text to the maximum length accepted by the model\n",
    "def truncate_text(text, max_length=512):\n",
    "    words = text.split()\n",
    "    if len(words) > max_length:\n",
    "        return \" \".join(words[:max_length])\n",
    "    return text\n",
    "\n",
    "# Function to analyze sentiment considering sarcasm\n",
    "def analyze_sentiment_with_sarcasm(text, is_sarcastic):\n",
    "    try:\n",
    "        truncated_text = truncate_text(text)\n",
    "        result = sentiment_pipeline(truncated_text)[0]\n",
    "        label = result['label']\n",
    "        \n",
    "        if is_sarcastic:\n",
    "            # Invert sentiment for sarcastic comments\n",
    "            if label == 'LABEL_0':\n",
    "                return 'Positive'\n",
    "            elif label == 'LABEL_2':\n",
    "                return 'Negative'\n",
    "            else:\n",
    "                return 'Neutral'\n",
    "        else:\n",
    "            if label == 'LABEL_0':\n",
    "                return 'Negative'\n",
    "            elif label == 'LABEL_1':\n",
    "                return 'Neutral'\n",
    "            else:\n",
    "                return 'Positive'\n",
    "    except Exception as e:\n",
    "        print(f\"Error in sentiment analysis for text: {text[:50]}...\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Function to process the dataframe\n",
    "def process_dataframe(df):\n",
    "    tqdm.pandas()\n",
    "    \n",
    "    # Analyze sentiment considering sarcasm\n",
    "    df['sentiment'] = df.progress_apply(lambda row: analyze_sentiment_with_sarcasm(row['cleaned_comment'], row['label'] == 1), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process the dataframe\n",
    "print(\"Analyzing sentiment...\")\n",
    "df_processed = process_dataframe(df_balanced)\n",
    "\n",
    "# Show sentiment distribution\n",
    "print(\"\\nSentiment distribution:\")\n",
    "print(df_processed['sentiment'].value_counts())\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSome analysis examples:\")\n",
    "sample_size = min(10, len(df_processed))\n",
    "for _, row in df_processed.sample(sample_size).iterrows():\n",
    "    print(f\"Original comment: {row['comment'][:100]}...\")\n",
    "    print(f\"Cleaned comment: {row['cleaned_comment'][:100]}...\")\n",
    "    print(f\"Sentiment: {row['sentiment']}\")\n",
    "    print(f\"Sarcastic: {'Yes' if row['label'] == 1 else 'No'}\\n\")\n",
    "\n",
    "# Save the result\n",
    "output_file = os.path.join('datasets', 'df_with_sentiment_and_sarcasm.csv')\n",
    "df_processed.to_csv(output_file, index=False)\n",
    "print(f\"\\nDataset with sentiment analysis considering sarcasm saved in {output_file}\")\n",
    "\n",
    "# Final statistics\n",
    "print(f\"\\nTotal rows: {len(df_processed)}\")\n",
    "print(f\"Sentiment distribution:\")\n",
    "print(df_processed['sentiment'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e22dcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment using VADER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [00:08<00:00, 23618.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment distribution (VADER):\n",
      "sentiment_vader\n",
      "Neutral     70195\n",
      "Negative    65833\n",
      "Positive    63972\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Some analysis examples:\n",
      "Original comment: You didn't take very many pictures apparently....\n",
      "Cleaned comment: you didnt take very many pictures apparently...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: My guess is the patriarchy protects them from it....\n",
      "Cleaned comment: my guess is the patriarchy protects them from it...\n",
      "Sentiment: Negative\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: What a terrible advice...\n",
      "Cleaned comment: what a terrible advice...\n",
      "Sentiment: Negative\n",
      "Sarcastic: No\n",
      "\n",
      "Original comment: Mother of Lions!...\n",
      "Cleaned comment: mother of lions...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: No\n",
      "\n",
      "Original comment: Ive given up on guitar a decade ago, please teach me theory so I can feel good about myself....\n",
      "Cleaned comment: ive given up on guitar a decade ago please teach me theory so i can feel good about myself...\n",
      "Sentiment: Negative\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: You know if they were playing the Red Wings that'd be a goalie misconduct penalty....\n",
      "Cleaned comment: you know if they were playing the red wings thatd be a goalie misconduct penalty...\n",
      "Sentiment: Positive\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: Yeah there is no room for nuance when looking at gun violence, a suicide is exactly the same as a sp...\n",
      "Cleaned comment: yeah there is no room for nuance when looking at gun violence a suicide is exactly the same as a spr...\n",
      "Sentiment: Positive\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: The era of true creativity...\n",
      "Cleaned comment: the era of true creativity...\n",
      "Sentiment: Negative\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: Obviously the solution for the Cech/Courtois dilema is to bring back the 5-4-1 and play cech as a sw...\n",
      "Cleaned comment: obviously the solution for the cechcourtois dilema is to bring back the  and play cech as a sweeper...\n",
      "Sentiment: Negative\n",
      "Sarcastic: Yes\n",
      "\n",
      "Original comment: That's gonna void the warranty...\n",
      "Cleaned comment: thats gonna void the warranty...\n",
      "Sentiment: Neutral\n",
      "Sarcastic: Yes\n",
      "\n",
      "\n",
      "Dataset with VADER sentiment analysis considering sarcasm saved in datasets\\df_with_sentiment_vader_and_sarcasm.csv\n",
      "\n",
      "Total rows: 200000\n",
      "Sentiment distribution (VADER):\n",
      "sentiment_vader\n",
      "Neutral      35.1%\n",
      "Negative    32.92%\n",
      "Positive    31.99%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to truncate text to the maximum length accepted by the model\n",
    "def truncate_text(text, max_length=512):\n",
    "    words = text.split()\n",
    "    if len(words) > max_length:\n",
    "        return \" \".join(words[:max_length])\n",
    "    return text\n",
    "\n",
    "# Function to analyze sentiment with VADER considering sarcasm\n",
    "def analyze_sentiment_vader_with_sarcasm(text, is_sarcastic):\n",
    "    try:\n",
    "        truncated_text = truncate_text(text)\n",
    "        sentiment_scores = sia.polarity_scores(truncated_text)\n",
    "        compound_score = sentiment_scores['compound']\n",
    "        \n",
    "        if is_sarcastic:\n",
    "            # Invert sentiment for sarcastic comments\n",
    "            compound_score = -compound_score\n",
    "        \n",
    "        if compound_score >= 0.05:\n",
    "            return 'Positive'\n",
    "        elif compound_score <= -0.05:\n",
    "            return 'Negative'\n",
    "        else:\n",
    "            return 'Neutral'\n",
    "    except Exception as e:\n",
    "        print(f\"Error in sentiment analysis for text: {text[:50]}...\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Function to process the dataframe\n",
    "def process_dataframe(df):\n",
    "    tqdm.pandas()\n",
    "    \n",
    "    # Analyze sentiment considering sarcasm\n",
    "    df['sentiment_vader'] = df.progress_apply(lambda row: analyze_sentiment_vader_with_sarcasm(row['cleaned_comment'], row['label'] == 1), axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process the dataframe\n",
    "print(\"Analyzing sentiment using VADER...\")\n",
    "df_processed = process_dataframe(df_balanced)\n",
    "\n",
    "# Show sentiment distribution\n",
    "print(\"\\nSentiment distribution (VADER):\")\n",
    "print(df_processed['sentiment_vader'].value_counts())\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nSome analysis examples:\")\n",
    "sample_size = min(10, len(df_processed))\n",
    "for _, row in df_processed.sample(sample_size).iterrows():\n",
    "    print(f\"Original comment: {row['comment'][:100]}...\")\n",
    "    print(f\"Cleaned comment: {row['cleaned_comment'][:100]}...\")\n",
    "    print(f\"Sentiment: {row['sentiment_vader']}\")\n",
    "    print(f\"Sarcastic: {'Yes' if row['label'] == 1 else 'No'}\\n\")\n",
    "\n",
    "# Save the result\n",
    "output_file = os.path.join('datasets', 'df_with_sentiment_vader_and_sarcasm.csv')\n",
    "df_processed.to_csv(output_file, index=False)\n",
    "print(f\"\\nDataset with VADER sentiment analysis considering sarcasm saved in {output_file}\")\n",
    "\n",
    "# Final statistics\n",
    "print(f\"\\nTotal rows: {len(df_processed)}\")\n",
    "print(f\"Sentiment distribution (VADER):\")\n",
    "print(df_processed['sentiment_vader'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa73ff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. All plots have been saved in the 'graphs' folder.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Create graphs directory if it doesn't exist\n",
    "os.makedirs('graphs', exist_ok=True)\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv('datasets/df_with_sentiment_and_sarcasm.csv')\n",
    "df2 = pd.read_csv('datasets/df_with_sentiment_vader_and_sarcasm.csv')\n",
    "\n",
    "# Custom sentence tokenizer\n",
    "def simple_sentence_tokenize(text):\n",
    "    return re.split(r'(?<=[.!?])\\s+', text)\n",
    "\n",
    "# Custom word tokenizer\n",
    "def simple_word_tokenize(text):\n",
    "    return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "# 1. Distribution Analysis\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "df1['sentiment'].value_counts().plot(kind='bar')\n",
    "plt.title('Sentiment Distribution (RoBERTa)')\n",
    "plt.subplot(122)\n",
    "df2['sentiment_vader'].value_counts().plot(kind='bar')\n",
    "plt.title('Sentiment Distribution (VADER)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/sentiment_distribution_comparison.png')\n",
    "plt.close()\n",
    "\n",
    "# 2. Wordcloud\n",
    "def create_wordcloud(text, title):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(text))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(f'graphs/{title.lower().replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "create_wordcloud(df1['cleaned_comment'], 'Wordcloud (All Comments)')\n",
    "create_wordcloud(df1[df1['label'] == 1]['cleaned_comment'], 'Wordcloud (Sarcastic Comments)')\n",
    "create_wordcloud(df1[df1['label'] == 0]['cleaned_comment'], 'Wordcloud (Non-Sarcastic Comments)')\n",
    "\n",
    "# 3. N-grams Analysis\n",
    "def get_ngrams(text, n):\n",
    "    words = simple_word_tokenize(text)\n",
    "    return zip(*[words[i:] for i in range(n)])\n",
    "\n",
    "def get_top_ngrams(text, n=1, top=10):\n",
    "    try:\n",
    "        all_ngrams = [ngram for comment in text for ngram in get_ngrams(comment, n)]\n",
    "        ngrams_freq = Counter(all_ngrams)\n",
    "        return ngrams_freq.most_common(top)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in get_top_ngrams: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def plot_ngrams(df, n, title, sentiment_column='sentiment'):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, sentiment in enumerate(['Positive', 'Neutral', 'Negative']):\n",
    "        top_ngrams = get_top_ngrams(df[df[sentiment_column] == sentiment]['cleaned_comment'], n)\n",
    "        if top_ngrams:\n",
    "            plt.subplot(3, 1, i+1)\n",
    "            sns.barplot(y=[' '.join(ng[0]) for ng in top_ngrams], x=[ng[1] for ng in top_ngrams], orient='h')\n",
    "            plt.title(f'Top {n}-grams ({sentiment})')\n",
    "            plt.xlabel('Frequency')\n",
    "            plt.ylabel('N-gram')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'graphs/{title.lower().replace(\" \", \"_\")}.png')\n",
    "    plt.close()\n",
    "\n",
    "for n in [1, 2, 3]:\n",
    "    plot_ngrams(df1, n, f'Top {n}-grams (RoBERTa)')\n",
    "    plot_ngrams(df2, n, f'Top {n}-grams (VADER)', sentiment_column='sentiment_vader')\n",
    "\n",
    "# 4. Sentiment Comparison\n",
    "sentiment_comparison = pd.crosstab(df1['sentiment'], df2['sentiment_vader'])\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(sentiment_comparison, annot=True, fmt='d', cmap='YlGnBu')\n",
    "plt.title('Sentiment Comparison: RoBERTa vs VADER')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/sentiment_comparison_heatmap.png')\n",
    "plt.close()\n",
    "\n",
    "# 5. Sarcasm vs Sentiment\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "sns.countplot(data=df1, x='sentiment', hue='label')\n",
    "plt.title('Sarcasm vs Sentiment (RoBERTa)')\n",
    "plt.subplot(122)\n",
    "sns.countplot(data=df2, x='sentiment_vader', hue='label')\n",
    "plt.title('Sarcasm vs Sentiment (VADER)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/sarcasm_vs_sentiment.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Analysis complete. All plots have been saved in the 'graphs' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472f6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base_conda_env] *",
   "language": "python",
   "name": "conda-env-base_conda_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
